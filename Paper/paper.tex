\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Blind Assistance System using an FPGA\\
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Omkar Nandan Choudhary}
\IEEEauthorblockA{\textit{Department of Electronics} \\
\textit{TCET}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{Ishaan Shinde}
\IEEEauthorblockA{\textit{Department of Electronics} \\
\textit{TCET}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{Arun Kumar Singh}
\IEEEauthorblockA{\textit{Department of Electronics} \\
\textit{TCET}\\
City, Country \\
email address or ORCID}
}

\maketitle

\begin{abstract}
Sighted guidance is arguably the most efficient way of guiding the
visually impaired. Sighted guidance system will provide haptic
feedback to the user about the obstacles in the user's path. To detect
these obstacles, different options are available for sensors. Among
these we are using a stereo camera to take advantage of its ability to
provide visual information about the user's surrounding and ultrasonic sensors placed strategically to estimate the distance between the user and the obstacle. This data is run
through a YOLO based algorithm which will be trained to detect
obstacles in the user's path and this will be relayed back to the user
using Haptic feedback. The FPGA can provide true parallel processing while maintaining
reconfigurability and programmability. This sensors will be mounted
on a standard white cane, reason being this piece of equipment is
already familiar and a part of the daily life for the visually impaired. This system will inform the user about obstacles in 5-8
meters range and will allow them to navigate around these obstacles
easily and safely.
\end{abstract}

\begin{IEEEkeywords}
Blind Assistance, FPGA, YOLO, Object Detection.
\end{IEEEkeywords} 

\section{Introduction}
Around 62 million people in India are visually impaired, for them performing even basic daily tasks is a challenge. An activity as simple as travelling, which is one of the most fundamental parts of our daily life, can become a havoc. Walking in an urban environment means there are several obstacles in the path, these may be fellow travellers, stray animals or some other obstacles. Navigating around these obstacles can be a problem for the visually impaired. Such inconveniences in travelling disrupts their daily life. This project aims to provide a solution for these issues faced by them.We focus our project on helping them navigate while walking. To do this, we are reinforcing the already in use walking stick used by them. We are planning to design a system which will be mounted on this stick and will enable them to micro-navigate in situations where relying only on a regular walking stick is not feasible. This system will see the path in front and will try to identify potential obstacles in the path and inform the user using haptic feedback. This will help them preemptively judge the surrounding layout and the approximate location of obstacles. Doing this will make it easier for them to travel and will save effort and time. 

\section{Literature Review}

%\subsection{}

Based on reports from WHO, the estimated count of visually impaired individuals in India is around 62 million. Since the year 2000, the count of visually impaired individuals has seen a steep rise across the years. This type of predicament makes it difficult for such individuals to survive normally without any external assistance. Over the years such assistance was provided by physical helpers such as a medical assistant, a pet, a relative, walking aids (such as a cane), etc. However, these types of assistance generally put a degree of dependence on other humans for the visually impaired individuals to perform even basic tasks. It is of utmost importance to innovate in the field of smart assistance for blind individuals as they add up to a large amount of the population of the country. As a part of our literature survey for the project, a range of designs were reviewed. For our project, due consideration of all the previously done research is made and a solution has been proposed accordingly.\newline
\newline[1].Smart Cane for Blind and Visually Impaired Persons. Year of Publishing:May, 2020 \newline
\newline The proposed work includes the design of a smart cane with multiple sensors connected to an Arduino board. ultrasonic and infrared sensors are mounted at appropriate locations to detect obstacles. A buzzer, vibrator, and some recorded audio clips to navigate the blind people safely.\newline
\newline[2].Design and Implementation of Mobility Aid for Blind People. Year of Publishing:August, 2015 \newline
\newline Draws attention to the shortcomings of already existing solutions. The proposed solution is a Jacket that has to be worn by the visually Impaired. The Jacket is mounted with a collection of ultrasonic Sensors to provide assistance to the user. \newline
\newline[3].Ultrasonic Navigation-based Blind Aid for the Visually Impaired. Year of Publishing:June, 2018
\newline The proposed system operates in two modes namely hurdle detection mode and fixed mode. In this mode, the system detects solid and liquid obstacles sending respective instructions to the blind person through voice messages via Bluetooth. The fixed mode provides the information and guidance to move from one place to another safely by setting a fixed route in blind stick from source to destination location. Additionally, the system uses GPS data, Bluetooth to assist the visually impaired. \newline
\newline[4].Survey on assistance systems and Navigation for Blind People using Sensors. Year of Publishing: January 2018. \newline
\newline A survey paper to understand the most reliable and efficient assistance systems for the visually impaired. \newline
\newline[5].A Stereo Vision System for Pedestrian Navigation. Year of Publishing: 2003. \newline
\newline In this paper, the project was implemented using Stereo cameras. For accurate motion estimation Gait analysis and ego-motion estimation, algorithms are used. \newline
\newline[6].A system for remote sighted guidance of visually impaired pedestrians. Year of Publishing: 2003. \newline
\newline In this paper, the authors designed the guidance system using GPS as the main navigation device. As shown in the paper the accuracy of this approach is not sufficient enough for users to be able to traverse an unknown path with ease. This is especially true in cases where obstacles are blocking the GPS signal. They have also proposed to use cameras to supplement the GPS device.


\section{Research Gaps}
The primary aim of this project is to develop a product to cater to visually impaired individuals in the Indian environment. However, the ergonomics of the final product needs to be optimized considering the ease and comfort of the end-user. The position of the sensors and the location of the final product will be of critical importance. The ease of use needs to be a priority when designing a device for the visually impaired. The device's power consumption should be optimized and justifiable, considering the hardware used and services provided to the end-user. Battery Pack of the right chemical composition and specifications should be incorporated to optimize battery health and minimize the re-charge frequency. The device should be easily tune able by the end-user and he/she should not require external assistance to use the device or modify its operation.\newline

%\subsection{Units}
%\begin{itemize}
%\item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
%\item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
%\item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
%\item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
%\end{itemize}

%\subsection{Equations}
% Number equations consecutively. To make your 
% equations more compact, you may use the solidus (~/~), the exp function, or 
% appropriate exponents. Italicize Roman symbols for quantities and variables, 
% but not Greek symbols. Use a long dash rather than a hyphen for a minus 
% sign. Punctuate equations with commas or periods when they are part of a 
% sentence, as in:
%\begin{equation}
%a+b=\gamma\label{eq}
%\end{equation}

% Be sure that the 
% symbols in your equation have been defined before or immediately following 
% the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at 
% the beginning of a sentence: ``Equation \eqref{eq} is . . .''

% \subsection{\LaTeX-Specific Advice}

% Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
% of ``hard'' references (e.g., \verb|(1)|). That will make it possible
% to combine sections, add equations, or change the order of figures or
% citations without having to go through the file line by line.

% Please don't use the \verb|{eqnarray}| equation environment. Use
% \verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
% environment leaves unsightly spaces around relation symbols.

% Please note that the \verb|{subequations}| environment in {\LaTeX}
% will increment the main equation counter even when there are no
% equation numbers displayed. If you forget that, you might write an
% article in which the equation numbers skip from (17) to (20), causing
% the copy editors to wonder if you've discovered a new method of
% counting.

% {\BibTeX} does not work by magic. It doesn't get the bibliographic
% data from thin air but from .bib files. If you use {\BibTeX} to produce a
% bibliography you must send the .bib files. 

% {\LaTeX} can't read your mind. If you assign the same label to a
% subsubsection and a table, you might find that Table I has been cross
% referenced as Table IV-B3. 

% {\LaTeX} does not have precognitive abilities. If you put a
% \verb|\label| command before the command that updates the counter it's
% supposed to be using, the label will pick up the last counter to be
% cross referenced instead. In particular, a \verb|\label| command
% should not go before the caption of a figure or a table.

% Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
% will not stop equation numbers inside \verb|{array}| (there won't be
% any anyway) and it might stop a wanted equation number in the
% surrounding equation.
\section{Ergonomics}
Over the years, a variety of innovations have come forward to cater to the visually impaired population. Some required the user to wear it on their upper body, eyewear, headgear, footwear, etc., or a combination of mentioned locations. Most of these mentioned solutions had their unique advantages and disadvantages. However, it was observed that most of these assistance devices required the end-user to adopt a completely new or different way of getting assistance. This process of learning and understanding the requirements of the assistant device takes time and effort from the end-user. It would be only correct if we think of providing assistance to such individuals that involve an item already familiar to them and thus requires less time and effort from the end-user. Here, we have presented an idea that provides the visually impaired individuals with a device that revolves around an object that they are familiar with, a walking cane. The target individuals are very familiar with the utility of a walking cane, most individuals also hold preliminary training on how to use a walking cane already. A smart walking cane that has a combination of sensors mounted on it to acquire the surrounding data can be used to provide the user with the necessary data and suggestions. Sensors such as a visual sensor (stereo camera) and an ultrasonic/IR Sensor for distance estimation between the user and an object in the path will be mounted on the cane. The received data will be sent to the main processing unit to then provide the user with the necessary suggestions. The primary reason behind selecting vibrations as a medium of providing feedback to the user is because from research over the years it has been found that people who have a visual disability by birth or develop It later due to various reasons have an enhanced sense of hearing and touch or at least rely more on their other senses to get an understanding of their surroundings. They are naturally better at identifying the source of any noise or any sound than any regular person could otherwise, and disrupting this by making the user wear an earphone or headwear for an audio alerts system might hamper the natural ability of the person. The incorporation of a walking cane as a solution would also make it conspicuous to the fellow pedestrians about the user's condition and suggest them to remain alert or cautious in case of any emergency or misshaping.

% \section{Ergonomics}
% Over the years, a variety of innovations have come forward to cater to the visually impaired population. Some required the user to wear it on their upper body, eyewear, headwear, footwear, etc., or a combination of mentioned locations. Most of these mentioned solutions had their unique advantages and disadvantages. However, it was observed that most of these assistance devices required the end-user to adopt a completely new or different way of getting assistance. This process of learning and understanding the requirements of the assistant device takes time and effort from the end-user. It would be only correct if we think of providing assistance to such individuals that involve an item already familiar to them and thus requires less time and effort from the end-user. Here, we have presented an idea that provides the visually impaired individuals with a device that revolves around an object that they are familiar with, a walking cane. The target individuals are very familiar with the utility of a walking cane, most individuals also hold preliminary training on how to use a walking cane already. A smart walking cane that has a combination of sensors mounted on it to acquire the surrounding data can be used to provide the user with the necessary data and suggestions. Sensors such as a visual sensor (stereo camera) and an ultrasonic/IR Sensor for distance estimation between the user and an object in the path will be mounted on the cane. The received data will be sent to the main processing unit to then provide the user with the necessary suggestions. The primary reason behind selecting vibrations as a medium of providing feedback to the user is because from research over the years it has been found that people who have a visual disability by birth or develop It later due to various reasons have an enhanced sense of hearing and touch or at least rely more on their other senses to get an understanding of their surroundings. They are naturally better at identifying the source of any noise or any sound than any regular person could otherwise, and disrupting this by making the user wear an earphone or headwear for an audio alerts system might hamper the natural ability of the person. The incorporation of a walking cane as a solution would also make it conspicuous to the fellow pedestrians about the user's condition and suggest them to remain alert or cautious in case of any emergency or misshaping.

\section{Methodology}\label{SCM}
In this project, the combination of a Field Programmable Gate Array (or FPGA) and an RGBD camera will be explored to get effective data about the surroundings of the user. The medium of haptic feedback will be used to alert the user. A 2V - 5V dc mini vibration motor will b e used. Haptic alerts are considered being one of the most preferred choices in types of feedbacks, as it eliminates the need for the user to wear any extra feedback equipment (like earphones, etc.) which might block or hamper the user’s natural ability of hearing. The Zigbee RF modules will be helpful in establishing communication between the main FPGA processing unit and the RGBD camera. Features of FPGAs like concurrent processing of data provide faster and reliable data at the outputs as compared to that of an Arduino or similar microcontroller boards. The RGB-D camera will be mounted on a general walking cane (for visually impaired), so the user doesn’t need to depend on or learn handling of any new equipment and can perform his or her task of daily commute with ease and assurance.

\subsection{Hardware}\label{AA}
\begin{itemize}
\item FPGA: Artix®-7 Family Artix®-7 devices provide the highest performance-per-watt fabric, transceiver line rates, DSP processing, and AMS integration in a cost-optimized FPGA. Features 1,066Mb/s DDR3 support, the family is the best value for a variety of cost and power-sensitive applications including software-defined radio, machine vision cameras, and low-end wireless backhaul.
\item RGB-D-Sensor – Microsoft Kinect Kinect is a device introduced in 2010 as an accessory to XBOX 360. The acquired data has different and complementary natures, combining geometry with visual attributes. For this reason, Kinect is a flexible tool that can be used in applications from several areas such as: Computer Graphics, Image processing, etc.
\item Vibration Motor This is a tiny round coin size vibration motor. Can be used to provide vibrational alerts. When powered, the vibration motor causes the attached surface to vibrate. This motor works with an input voltage as low as 2.5V. It has wire leads coming out.
\item Regular cane A regular cane for visual impaired can be used to mount the sensors and vibration motor for feedback to the user.
\item Zigbee transceiver module The wireless transmission will be required to establish communication between the FPGA board and the sensors. XBee and XBee-PRO ZigBee RF modules provide cost effective wireless connectivity to electronic devices. XBee and XBee-PRO ZigBee modules are ideal for applications in the energy and controls markets where manufacturing efficiencies are critical. The Serial Peripheral Interface (SPI) provides a high-speed interface and optimizes integration with embedded microcontrollers, lowering development costs and reducing time to market. Products in the XBee family require little to no configuration or additional development. 
\end{itemize}

\subsection{Software}
\begin{itemize}
\item XCTU is a free multi-platform application designed to enable developers to interact with Digi RF modules through a simpleto-use graphical interface. It includes new tools that make it easy to set-up, configure and test XBEE RF modules. XCTU includes all of the tools a developer needs to quickly get up and running with XBee. Unique features like graphical network view, which graphically represents the XBee network along with the signal strength of each connection, and the XBee API frame builder, which intuitively helps to build and interpret API frames for XBees being used in API mode, combine to make development on the XBee platform easier than ever. This application will be used to communicate with Zigbee RF modues.
\item The Xilinx Software Development Kit (XSDK) is the Integrated Design Environment for creating embedded applications on any of Xilinx's microprocessors. The SDK is the first application IDE to deliver true homogenous and heterogeneous multi-processor design, debug, and performance analysis. This application will be used for interacting and programming the FPGA.
\end{itemize}



% \subsection{Authors and Affiliations}
% \textbf{The class file is designed for, but not limited to, six authors.} A 
% minimum of one author is required for all conference articles. Author names 
% should be listed starting from left to right and then moving down to the 
% next line. This is the author sequence that will be used in future citations 
% and by indexing services. Names should not be listed in columns nor group by 
% affiliation. Please keep your affiliations as succinct as possible (for 
% example, do not differentiate among departments of the same organization).

% \subsection{Identify the Headings}
% Headings, or heads, are organizational devices that guide the reader through 
% your paper. There are two types: component heads and text heads.

% Component heads identify the different components of your paper and are not 
% topically subordinate to each other. Examples include Acknowledgments and 
% References and, for these, the correct style to use is ``Heading 5''. Use 
% ``figure caption'' for your Figure captions, and ``table head'' for your 
% table title. Run-in heads, such as ``Abstract'', will require you to apply a 
% style (in this case, italic) in addition to the style provided by the drop 
% down menu to differentiate the head from the text.

% Text heads organize the topics on a relational, hierarchical basis. For 
% example, the paper title is the primary text head because all subsequent 
% material relates and elaborates on this one topic. If there are two or more 
% sub-topics, the next level head (uppercase Roman numerals) should be used 
% and, conversely, if there are not at least two sub-topics, then no subheads 
% should be introduced.

% \subsection{Figures and Tables}
% \paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
% bottom of columns. Avoid placing them in the middle of columns. Large 
% figures and tables may span across both columns. Figure captions should be 
% below the figures; table heads should appear above the tables. Insert 
% figures and tables after they are cited in the text. Use the abbreviation 
% ``Fig.~\ref{fig}'', even at the beginning of a sentence.

% \begin{table}[htbp]
% \caption{Table Type Styles}
% \begin{center}
% \begin{tabular}{|c|c|c|c|}
% \hline
% \textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
% \cline{2-4} 
% \textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
% \hline
% copy& More table copy$^{\mathrm{a}}$& &  \\
% \hline
% \multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
% \end{tabular}
% \label{tab1}
% \end{center}
% \end{table}

% \begin{figure}[htbp]
% \centerline{\includegraphics{fig1.png}}
% \caption{Example of a figure caption.}
% \label{fig}
% \end{figure}

% Figure Labels: Use 8 point Times New Roman for Figure labels. Use words 
% rather than symbols or abbreviations when writing Figure axis labels to 
% avoid confusing the reader. As an example, write the quantity 
% ``Magnetization'', or ``Magnetization, M'', not just ``M''. If including 
% units in the label, present them within parentheses. Do not label axes only 
% with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization 
% \{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of 
% quantities and units. For example, write ``Temperature (K)'', not 
% ``Temperature/K''.

% \section*{Acknowledgment}

% The preferred spelling of the word ``acknowledgment'' in America is without 
% an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B. 
% G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor 
% acknowledgments in the unnumbered footnote on the first page.

% \section*{References}

% Please number citations consecutively within brackets \cite{b1}. The 
% sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
% number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
% the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

% Number footnotes separately in superscripts. Place the actual footnote at 
% the bottom of the column in which it was cited. Do not put footnotes in the 
% abstract or reference list. Use letters for table footnotes.

% Unless there are six authors or more give all authors' names; do not use 
% ``et al.''. Papers that have not been published, even if they have been 
% submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
% that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
% Capitalize only the first word in a paper title, except for proper nouns and 
% element symbols.

% For papers published in translation journals, please give the English 
% citation first, followed by the original foreign-language citation \cite{b6}.

% \begin{thebibliography}{00}
% \bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
% \bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
% \bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
% \bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
% \bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
% \bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
% \bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
% \end{thebibliography}
% \vspace{12pt}
% \color{red}
% IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
